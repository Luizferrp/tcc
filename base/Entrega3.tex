\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage[portuguese]{babel}
\usepackage[colorlinks=true,allcolors=black]{hyperref}
\usepackage[acronym]{glossaries}
\usepackage{enumerate}% http://ctan.org/pkg/enumerate

% não permite separar acrônimo em duas linhas (só a sigla estar na outra linha)
\newacronymstyle{long-short-br}
{%
  \GlsUseAcrEntryDispStyle{long-short}%
}%
{%
  \GlsUseAcrStyleDefs{long-short}%  
  \renewcommand*{\genacrfullformat}[2]{%
    \glsentrylong{##1}##2~\textup{(\firstacronymfont{\glsentryshort{##1}})}%
  }%
  \renewcommand*{\Genacrfullformat}[2]{%
    \Glsentrylong{##1}##2~\textup{(\firstacronymfont{\glsentryshort{##1}})}%
  }%
  \renewcommand*{\genplacrfullformat}[2]{%
    \glsentrylongpl{##1}##2~\textup{(\firstacronymfont{\glsentryshortpl{##1}})}%
  }%
  \renewcommand*{\Genplacrfullformat}[2]{%
    \Glsentrylongpl{##1}##2~\textup{(\firstacronymfont{\Glsentryshortpl{##1}})}%
  }%
}
\setacronymstyle{long-short-br}


\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{array}
\usepackage{booktabs}
\usepackage{soul}
\setuldepth{Berlin}


\definecolor{headercolor}{RGB}{220,220,220} % Cinza espacial para cabeçalhos
\definecolor{rowcolor}{RGB}{245,245,245} % branco lua para linhas alternadas
\newcommand\red[1]{{\textcolor{red}{#1}}}

\frenchspacing

\sloppy
\begin{document}

\input{acronyms} % importa os acrônimos de acronyms.tex

\title{Especificação Formal da Solução\\
\vspace{0.4cm}
Detecção de Intrusão de Redes em CNNs para hardwares limitados\\
\vspace{0.4cm}
{\Large Projeto de Pesquisa Científica\\
Experiência Criativa: Projeto Transformador I\\
Bacharelado em Ciência da Computação -- PUCPR\\
2025}}

\author{
    Turma {U} -- Equipe {3} \\
    Eduarda Dallagrana, Henrique Conceição, Kaua Nunes, Luiz Pereira\\
    {\centering\small dudadallagrana@gmail.com, l.pereira22@pucpr.edu.br, kauanunnes@hotmail.com, henrique.conceicao19.hc@gmail.com}
}


\maketitle

\section{Método Proposto}

    Este trabalho propõe uma comparação entre abordagens voltada à detecção de intrusões em redes computacionais utilizando Redes Neurais Convolucionais (CNNs), com foco na viabilidade de implementação em ambientes com recursos computacionais limitados. A principal motivação está na capacidade das CNNs de identificar padrões complexos de tráfego malicioso com alta precisão, mesmo com hardwares limitados.

    Utilizou-se como base de dados o NSL-KDD, amplamente reconhecido após a kdd cup, para avaliação de sistemas de detecção de intrusão. NSL-KDD é um dataset para treinamento de detecção de intrusões em redes, versão revisada e refinada do conjunto de dados KDD'99, removendo vários de seus problemas integrais, principalmente as réplicas de registros. O NSL-KDD foi desenvolvido proporcionando uma base de dados mais robusta\cite{b15}.
    Este conjunto de dados também é um conjunto de dados de 41 recursos com os ataques divididos em quatro classes:\textit{ Denial of Service }(DoS),\textit{ Probe},\textit{ Remote to Local} (R2L), and \textit{User to Root} (U2R). A seção\textit{ Dados Utilizados} fornece mais informações.
    
    E para a implementação foi escolhido o uso de Python por ter se tornado uma das mais populares quando o assunto é aprendizado de máquina e ciência de dados, especialmente devido ao suporte robusto a bibliotecas especializadas\cite{b14}. Todos os classificadores profundos foram implementados  utilizando as bibliotecas PyTorch (com suporte CUDA ou MPS para suporte a aceleração por hardware). Além das CNNs, também avaliamos a eficácia de classificadores tradicionais, desenvolvidos com Scikit-learn, como K-Nearest Neighbors (KNN), Decision Tree e Random Forest, com o objetivo de comparar seu desempenho em relação à solução baseada em Deep Learning.

\subsection{Visão Geral do Método Proposto}
    
    Os estudos mostraram que as principais direções de pesquisa para detectar ataques de dia zero baseia-se na detecção de outliers
    (ou seja, instâncias/ocorrências que diferem do tráfego benigno). No entanto, a principal desvantagem das
    técnicas de detecção baseadas em outliers disponíveis é sua precisão relativamente baixa\cite{b5}. A metodologia explora a capacidade das CNNs em gerneralizar o aprendizado\cite{b6}, ideal para zero days, e compara com esses modelos classicos que dependem de classes existentes\cite{b7}, visando um modelo ainda leve e eficaz na detecção de padrões anômalos no tráfego de rede.
    
    O pré-processamento dos dados do conjunto NSL-KDD envolvelvel LabelEncoder dos dados categóricos e normalização principalmente para permitir melhor performace de classificadores rasos que dependem dessa caracteristica; as CNN utilizam esses mesmos dados, porém passado por um método extra que o transforma em imagem. O modelo baseado em convolucão é então desenvolvido com uma arquitetura otimizada para problema de alta escala, adaptando camadas convolucionais ao formato tabular dos dados e aplicando regularização para melhorar a generalização. Usando modelos estado da arte como Alexnet e GoogleLeNet para aprendizagem.

    A \textit{Figura 1} apresenta uma visão geral do fluxo do método proposto. O processo inicia-se pela aquisição e preparação dos dados, seguida pela divisão em conjuntos de treino e teste. A partir disso, são aplicadas duas abordagens paralelas: uma utilizando modelos convencionais e outra com redes neurais convolucionais, que passam por um método extra de tranformação em imagem. As métricas de desempenho são utilizadas para avaliar os resultados de cada modelo, conforme será discutido sucintamente no módulo \textit{Protocolo Experimental}.

    Por meio dessa abordagem comparativa, o trabalho busca validar a eficácia das CNNs em contextos com limitações e analisar criticamente sua aplicabilidade em relação a soluções mais tradicionais, visando contribuir para a criação de sistemas de detecção de intrusões mais robustos e eficientes.
    
    \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{fluxo_metodo.jpeg}
        \caption{Fluxo geral do método proposto }
        \label{fig:enter-label}
    \end{figure}

\subsection{Dados Utilizados}
      
    A escolha do dataset NSL-KDD justifica-se pela sua relevância, estrutura balanceada e ampla quantidade de registros (\textit{Tabela 1} \textit{Tabela 2}) e dados de tráfego de rede, que permitem treinamento e avaliação confiáveis\cite{b13}, essenciais para classificação genérica de um tipo "attack" aceitação na literatura científica, servindo como uma base sólida para o desenvolvimento de modelos de detecção de intrusões mais eficazes e generalizáveis.
    Nesta pesquisa, foi utilizado o conjunto de dados NSL-KDD, comum em sistemas de detecção de intrusões em redes. O dataset possui 41 atributos, divididos em três categorias: 

    \begin{itemize}
        \item Atributos básicos, como a duração da conexão, o protocolo de transporte utilizado e o volume de bytes transmitidos;
        \item Atributos derivados, como o número de conexões simultâneas com o mesmo host, erros de fragmentação e número de tentativas de conexão;
        \item Atributos de conteúdo, que fornecem informações detalhadas da atividade de rede, como tentativas de login mal-sucedidas e acessos a arquivos sensíveis, sendo particularmente relevantes para a identificação de padrões maliciosos.
    \end{itemize}
    
    A variável-alvo para o modelo de classificação foi a coluna attack, que foi transformada em binária, representando ataques (True) ou tráfego legítimo (False).

    Durante o pré-processamento dos dados, foram realizadas as etapas de normalização do conjunto de dados utilizando o MaxAbsScaler e o LabelEncoder para variáveis numéricas, permitindo tanto a cnn interpretar corretamente a dimensionalidade ao converter em imagem (\textit{Figura 2}), quanto modelos rasos não terem vieses quanto ao uniformalização da escala dos atributos e preservar a influência de valores extremos (outliers - possiveis attacks).
    \end{itemize}  
    
    \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{NormalAtaque.jpeg}
        \caption{Exemplo de entrada da CNN, Ataque X Normal }
        \label{tab:attack_datasets}
    \end{figure}

    Os ataques registrados no NSL-KDD estão classificados em quatro categorias principais:
    
    \begin{itemize}
        \item DoS (Denial of Service): ataques voltados à indisponibilização de recursos do sistema, com seis classes;
         \item R2L (Remote to Local): tentativas de acesso remoto não autorizado a sistemas locais, com sete classes;
         \item U2R (User to Root): escalonamento de privilégios de um usuário comum para privilégios de administrador (root), com cinco classes;
         \item Probe: varreduras na rede com o objetivo de identificar possíveis vulnerabilidades, com quatro classes.
    \end{itemize}

\hspace{1cm}

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|c|l|}
    \hline
    \rowcolor[HTML]{C0C0C0} 
    \textbf{Dataset} & \textbf{Ano} & \textbf{Tipos de Ataque} & \textbf{Ataques} \\ \hline
    NSL-KDD & 2009 & 4 & DoS,  R2L, U2R, Probe\\ \hline
    \end{tabular}
    \caption{Tipos de ataque | NSL-KDD}
    \label{tab:attack_datasets}
\end{table}

    \begin{table}[h]
    \centering
    \begin{tabular}{|l|c|l|}
    \hline
    \rowcolor[HTML]{C0C0C0} 
    \textbf{Classe} & \textbf{Quantidade} & \textbf{Categoria} \\ \hline
    buffer\_overflow & 30 & U2R \\ \hline
    loadmodule & 9 & U2R \\ \hline
    perl & 3 & U2R \\ \hline
    rootkit & 10 & U2R \\ \hline
    spy & 2 & U2R \\ \hline
    ftp\_write & 8 & R2L \\ \hline
    guess\_passwd & 53 & R2L \\ \hline
    imap & 11 & R2L \\ \hline
    multihop & 7 & R2L \\ \hline
    phf & 4 & R2L \\ \hline
    warezclient & 890 & R2L \\ \hline
    warezmaster & 20 & R2L \\ \hline
    ipsweep & 3599 & Probe \\ \hline
    nmap & 1493 & Probe \\ \hline
    portsweep & 2931 & Probe \\ \hline
    satan & 3633 & Probe \\ \hline
    back & 956 & DoS \\ \hline
    land & 18 & DoS \\ \hline
    neptune & 41214 & DoS \\ \hline
    pod & 201 & DoS \\ \hline
    smurf & 2646 & DoS \\ \hline
    teardrop & 892 & DoS \\ \hline
    normal & 67343 & normal \\ \hline
    \end{tabular}
    \caption{Categorias de Ataque}
    \label{tab:attack_datasets}
\end{table}
        

\subsection{Modelos ou Algoritmos Aplicados}

Foram utilizados principalmente dois frameworks: Torch e Scikit learn, para classificadores rasos e profundos respectivamente.

Os Foram utilizados dois modelos clássicos de redes neurais convolucionais (CNN): 
    A AlexNet é uma rede neural convolucional profunda estado da arte quanto a detecção de componentes
    
    A GoogleLeNet introduziu a ideia de módulos Inception, permitindo uma maior profundidade e complexidade na arquitetura da rede.
    
    Ambas as arquiteturas foram escolhidas devido à sua eficácia comprovada em tarefas de classificação de imagens e sua capacidade de lidar com grandes volumes de dados, tornando-as adequadas para a detecção de intrusões em redes.
    Além disso, foram utilizados três classificadores tradicionais: K-Nearest Neighbors (KNN, usando 5 vizinhos), Decision Tree e Random Forest. O KNN é um algoritmo de aprendizado supervisionado que classifica os dados com base na proximidade a outros pontos de dados, enquanto a Decision Tree utiliza uma estrutura hierárquica para tomar decisões com base em atributos dos dados. O Random Forest combina múltiplas árvores de decisão para melhorar a precisão e reduzir o risco de overfitting.
    Esses classificadores foram escolhidos devido à sua simplicidade e eficácia em tarefas de classificação, além de serem amplamente utilizados na literatura científica\cite{b6}. A comparação entre os modelos clássicos e as CNNs permitirá avaliar a eficácia das abordagens tradicionais em relação às técnicas mais avançadas de aprendizado profundo, contribuindo para a identificação de soluções mais robustas e eficientes na detecção de intrusões em redes.


\subsection{Ambiente de Execução}

As condições de execução dos experimentos foram realizadas em um ambiente computacional que requer as seguintes caracteristicas:
cpu, nesse caso foram usados 4/8 cores/threads de alta performace, especialmente para o treinamento de modelos de aprendizado raso, 
Hardware com suporte a CUDA ou MPS para aceleração de hardware, especialmente para o treinamento de modelos de aprendizado profundo, como as CNNs. O sistema operacional utilizado foi Linux com a kernel 6.13.
a quantidade de ram recomendada é de 16GB, com 8GB de swap, para garantir que o sistema tenha memória suficiente para lidar com os dados e os modelos durante o treinamento e a inferência. Além de pelo menos 2gb de vram
Expecialmente no caso de VRAM, no caso de mais ou menos (especialmente no caso de MPS que pode ser configurado pra usar a RAM de forma compartilhada ainda tendo alta bandwidth) o tamanho do batch pode ser ajustado para garantir que o modelo funcione corretamente. O tamanho do batch é um parâmetro importante que afeta o desempenho e a eficiência do treinamento de modelos de aprendizado profundo. Um tamanho de batch muito grande pode levar a problemas de memória, enquanto um tamanho muito pequeno pode resultar em um treinamento mais lento e menos eficiente, ja que isso limita o processo de transição dos modelos de uma lado a outro. no entanto o tempo de avaliação em si de cada sample não deve ser afetado.
O modelo exato da cpu e da gpu devem afetar o resultado de forma linear, mas proporcionamente a compação deve se manter, para efeitos de comparação, foi usado um I5 10th com uma MX250. 

Os requisitos de software incluem a instalação do Python 3.8 ou superior, juntamente com as bibliotecas necessárias, como PyTorch, Scikit-learn, Pandas e Matplotlib e Drivers Cuda compativeis com a versão do Torch escolhida, da qual deve ser principalmente compátivel com as kernels nn do Torch que são as utilizadas no projeto.

Algumas bibliotecas extras podem ter ser adicionadas para efeitos visuais durante o treinamento, mas nao ligadas com o tempo de treino ou avaliação.

\subsection{Protocolo Experimental}

    Para validar a eficácia da solução proposta, adotou-se um protocolo experimental, com foco na avaliação quantitativa baseada em métricas recorrentes na literatura em Aprendizado de Máquina e Aprendizado Profundo. As métricas de desempenho utilizadas foram derivadas da matriz de confusão(\textit{Tabela 3}), a qual relaciona as classes reais e previstas pelos modelos. Essa matriz é composta por quatro elementos fundamentais:
    
    \hspace{1cm}
    \begin{enumerate}[I]
    \item Verdadeiro Positivo (VP): instâncias corretamente classificadas como ataque;
    \item Falso Negativo (FN): ataques incorretamente classificados como tráfego normal;
    \item Falso Positivo (FP): instâncias normais incorretamente classificadas como ataque;
    \item Verdadeiro Negativo (VN): instâncias corretamente classificadas como normais.
    \end{enumerate}
    \hspace{1cm}

    Com base nesses valores, calcularam-se as seguintes métricas:
    
    \hspace{1cm}
    
    Precisão (Precision): razão entre os ataques corretamente identificados e todas as instâncias classificadas como ataque:

    \begin{equation}
    \text { Precisão }=\frac{V P}{V P+F P}
    \end{equation}
    \hspace{1cm}
    
    Revocação (Recall) ou Taxa de Detecção: razão entre os ataques corretamente identificados e o total de ataques reais:

    \begin{equation}
    \text { Revocação }=\frac{V P}{V P+F N}
    \end{equation}
    \hspace{1cm}
    
    Taxa de Falso Alarme (False Alarm Rate): razão entre instâncias normais incorretamente classificadas como ataques e o total de instâncias normais:

    \begin{equation}
    \text { Taxa de Falso Alarme }=\frac{F P}{F P+V N}
    \end{equation}
    \hspace{1cm}
    
    Taxa de Verdadeiro Negativo (True Negative Rate): razão entre instâncias normais corretamente classificadas e o total de instâncias normais:

    \begin{equation}
    \text { Taxa de Verdadeiro Negativo }=\frac{V N}{V N+F P}
    \end{equation}
    \hspace{1cm}
    
    Acurácia (Accuracy): razão entre todas as classificações corretas (ataques e normais) e o total de instâncias:

    \begin{equation}
    \text { Acurácia }=\frac{V P+V N}{V P+V N+F P+F N}
    \end{equation}
    \hspace{1cm}

    Tempo de Treinamento (Training Time): soma das diferenças entre o tempo de término e o tempo de início de cada batch durante o treinamento.
    
    Tempo de Inferência por Objeto (Inference Time): média das diferenças de tempo entre o início e o fim de cada rodada de inferência, dividida pela quantidade de objetos (imagens) em cada batch.
    

    \begin{table}[h]
        \centering
        \renewcommand{\arraystretch}{1.4}
        \rowcolors{3}{gray!15}{white}
        \begin{tabular}{|c|c|c|}
            \hline
            \rowcolor{gray!30}
            \multicolumn{1}{|c|}{} & \multicolumn{2}{c|}{\textbf{Classe Prevista}} \\ \hline
            \rowcolor{gray!30}
            \textbf & \textbf{Ataque} & \textbf{Normal} \\ \hline
            \textbf{Ataque} & Verdadeiro Positivo & Falso Negativo \\ \hline
            \textbf{Normal} & Falso Positivo & Verdadeiro Negativo \\ \hline
        \end{tabular}
        \caption{Matriz de confusão}
        \label{tab:matriz-confusao}
    \end{table}


    Essas métricas foram aplicadas na avaliação de desempenho dos modelos sobre conjuntos de dados públicos de referência, amplamente utilizados na área de detecção de intrusos em redes. Os experimentos incluíram a divisão dos dados em subconjuntos de treino e teste, utilizando a estratégia de validação cruzada, garantindo a imparcialidade dos resultados, alinhando o protocolo experimental aos objetivos e hipóteses do trabalho.
    
    O protocolo também considerou o trade-off entre desempenho e complexidade dos classificadores. Modelos rasos, como KNN e Random Forest, são eficientes com baixo custo computacional e mitigam parcialmente falhas frente a ataques desconhecidos, o KNN via clusterização e o Random Forest por meio de modelos especializados. No entanto, esses métodos dependem de padrões previamente conhecidos e podem falhar em cenários zero-day. Por isso, adotou-se o uso de CNNs, que reconhecem padrões contextuais e generalizam melhor, oferecendo maior robustez na detecção de ataques inéditos, ainda que com maior custo computacional.





\textbf{Não esqueça de habilitar a seções de referências, ok !?}

\begin{thebibliography}{00}


    \bibitem{b1}BISWAS, Saroj Kr. Intrusion Detection Using Machine Learning: A Comparison Study. 2018. NIT Silchar.
    
    \bibitem{b2}AHMAD, Zeeshan et al. Network intrusion detection system: A systematic study of machine learning and deep learning approaches. 2020. UniversitiMalaysia Sarawak.
    
    \bibitem{b3} Nathan Shone; Tran Nguyen Ngoc; Vu Dinh Phai; Qi Shi  (February 2018), ''A Deep Learning Approach to Network Intrusion Detection'', Australian Journal of Mechanical Engineering, IEEE Transactions on Emerging Topics in Computational Intelligence ( Volume: 2, Issue: 1, February 2018)
    
    \bibitem{b4} Springer, Berlin, Heidelberg, ''Early Stopping - But When?'' Part of the book series: Lecture Notes in Computer Science ((LNCS,volume 1524))
    
    \bibitem{b5} Hanan Hindy,Robert Atkinson, Christos Tachtatzis,Jean-Noël Colin, Ethan Bayne, and Xavier Bellekens, (14 October 2020), ''Utilising Deep Learning Techniques for Effective Zero-Day Attack Detection'' ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS, doi: https://doi.org/10.3390/electronics9101684
    
    \bibitem{b6} Akinul Islam Jony, Arjun Kumar Bose Arnob, (August 8, 2024), ''Securing the Internet of Things: Evaluating Machine Learning Algorithms for Detecting IoT Cyberattacks Using CIC-IoT2023 Dataset'', DOI: 10.5815/ijitcs.2024.04.04
    
    \bibitem{b7} Deepa Krishnan, Pravin Shrinath, 14 February 2024, ''Robust Botnet Detection Approach for Known and Unknown Attacks in IoT Networks Using Stacked Multi-classifier and Adaptive Thresholding''
    
    \bibitem{b8} Akinul Islam Jony, Arjun Kumar Bose Arnob, 2024 (Volume 16, Issue 4, pp.56-65), ''Securing the Internet of Things: Evaluating Machine Learning Algorithms for Detecting IoT Cyberattacks Using CIC-IoT2023 Dataset''
    
    \bibitem{b9} Charles Westphal, (18 Nov 2024), ''Feature Selection for Network Intrusion Detection'', https://doi.org/10.48550/arXiv.2411.11603
    
    \bibitem{b10} A. Pasumpon Pandian, 2021, ''Performance Evaluation and Comparison using Deep Learning Techniques in Sentiment Analysis'', DOI: https://doi.org/10.36548/jscp.2021.2.006
    
    \bibitem{b11} Sailesh Kumar, 19 Dec 2007, ''Survey of Current Network Intrusion Detection Techniques'', http://www.cse.wustl.edu/~jain/cse571-07/ftp/ids/
    
    \bibitem{b12} Nasrin Sultana1, Naveen Chilamkurti1, Wei Peng2, Rabei Alhadad, 26 December 2017, ''Survey on SDN based network intrusion detection system sing machine learning approaches'', https://doi.org/10.1007/s12083-017-0630-0
    
    \bibitem{b13} Hari Mohan Rai 1 , Joon Yoo 1,* and Saurabh Agarwal, 11 December 2024, ''The Improved Network Intrusion Detection Techniques Using the Feature Engineering Approach with, Boosting Classifiers'', https://www.mdpi.com/2227-7390/12/24/3909

    \bibitem{b14} Nagpal, A.; Gabrani, G. (2019), ''Python for Data Analysis'', Springer, Berlin, Heidelberg, doi:10.1007/978-3-030-15688-0.
    
    \bibitem{b15} Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A. Ghorbani, 2009, ''A detailed analysis of the KDD CUP 99 data set'', IEEE Symposium on Computational Intelligence for Security and Defense Applications, Ottawa, ON, Canada, pp. 1-6, doi: 10.1109/CISDA.2009.5356528.
    
\end{thebibliography}

% GENERAL Python FAQ — Python 3.7.4 documentation. <https://docs.python.
% org/3/faq/general.html#what-is-python>. Accessed: 2019-07-20.


\end{document}